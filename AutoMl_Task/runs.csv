Start Time,Duration,Run ID,Name,Source Type,Source Name,User,Status,Tokenizer,__cached__setup_devices,_attn_implementation_autoset,_n_gpu,_name_or_path,accelerator_config,adafactor,adam_beta1,adam_beta2,adam_epsilon,add_cross_attention,architectures,attention_bias,attention_dropout,auto_find_batch_size,average_tokens_across_devices,bad_words_ids,batch_eval_metrics,begin_suppress_tokens,bf16,bf16_full_eval,bos_token_id,chunk_size_feed_forward,cross_attention_hidden_size,data_seed,dataloader_drop_last,dataloader_num_workers,dataloader_persistent_workers,dataloader_pin_memory,dataloader_prefetch_factor,ddp_backend,ddp_broadcast_buffers,ddp_bucket_cap_mb,ddp_find_unused_parameters,ddp_timeout,debug,decoder_start_token_id,deepspeed,deepspeed_plugin,disable_tqdm,dispatch_batches,distributed_state,diversity_penalty,do_eval,do_predict,do_sample,do_train,dtype,early_stopping,encoder_no_repeat_ngram_size,eos_token_id,eval_accumulation_steps,eval_delay,eval_do_concat_batches,eval_on_start,eval_steps,eval_strategy,eval_use_gather_object,evaluation_strategy,exponential_decay_length_penalty,finetuning_task,forced_bos_token_id,forced_eos_token_id,fp16,fp16_backend,fp16_full_eval,fp16_opt_level,fsdp,fsdp_config,fsdp_min_num_params,fsdp_transformer_layer_cls_to_wrap,full_determinism,gradient_accumulation_steps,gradient_checkpointing,gradient_checkpointing_kwargs,greater_is_better,group_by_length,half_precision_backend,head_dim,hidden_act,hidden_size,hub_always_push,hub_model_id,hub_private_repo,hub_strategy,hub_token,id2label,ignore_data_skip,include_for_metrics,include_inputs_for_metrics,include_num_input_tokens_seen,include_tokens_per_second,initializer_range,intermediate_size,is_decoder,is_encoder_decoder,jit_mode_eval,label2id,label_names,label_smoothing_factor,learning_rate,length_column_name,length_penalty,load_best_model_at_end,load_in_4bit,local_rank,loftq_config,log_level,log_level_replica,log_on_each_node,logging_dir,logging_first_step,logging_nan_inf_filter,logging_steps,logging_strategy,lora_alpha,lora_dropout,lr_scheduler_kwargs,lr_scheduler_type,max_grad_norm,max_length,max_position_embeddings,max_seq_length,max_steps,metric_for_best_model,min_length,mlp_bias,model_name,model_type,mp_parameters,neftune_noise_alpha,no_cuda,no_repeat_ngram_size,num_attention_heads,num_beam_groups,num_beams,num_hidden_layers,num_key_value_heads,num_return_sequences,num_train_epochs,optim,optim_args,optim_target_modules,output_attentions,output_dir,output_hidden_states,output_scores,overwrite_output_dir,pad_token,pad_token_id,padding_side,past_index,per_device_eval_batch_size,per_device_train_batch_size,per_gpu_eval_batch_size,per_gpu_train_batch_size,prediction_loss_only,prefix,pretraining_tp,problem_type,pruned_heads,push_to_hub,push_to_hub_model_id,push_to_hub_organization,push_to_hub_token,quantization_config,r,random_state,ray_scope,remove_invalid_values,remove_unused_columns,repetition_penalty,report_to,restore_callback_states_from_checkpoint,resume_from_checkpoint,return_dict,return_dict_in_generate,rms_norm_eps,rope_scaling,rope_theta,run_name,save_on_each_node,save_only_model,save_safetensors,save_steps,save_strategy,save_total_limit,seed,sep_token_id,skip_memory_metrics,split_batches,suppress_tokens,task_specific_params,temperature,tf32,tf_legacy_loss,tie_encoder_decoder,tie_word_embeddings,tokenizer_class,top_k,top_p,torch_compile,torch_compile_backend,torch_compile_mode,torch_dtype,torch_empty_cache_steps,torchdynamo,torchscript,tpu_metrics_debug,tpu_num_cores,transformers_version,typical_p,unsloth_version,use_bfloat16,use_cache,use_cpu,use_gradient_checkpointing,use_ipex,use_legacy_prediction_loop,use_liger_kernel,use_mps_device,use_rslora,vocab_size,warmup_ratio,warmup_steps,weight_decay,epoch,eval_loss,eval_runtime,eval_samples_per_second,eval_steps_per_second,grad_norm,learning_rate,loss,total_flos,train_loss,train_runtime,train_samples_per_second,train_steps_per_second,training_loss,validation_loss,model_name
2024-11-17 16:29:00,,e36e01a8e14a4fd6b272143744149d9c,illustrious-colt-932,LOCAL,/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py,root,RUNNING,PreTrainedTokenizerFast,cuda:0,True,1,unsloth/Llama-3.2-3B-Instruct-bnb-4bit,"AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False)",False,0.9,0.999,1e-08,False,['LlamaForCausalLM'],False,0.0,False,False,None,False,None,False,False,128000,0,None,None,False,0,False,True,None,None,None,None,None,1800,[],None,None,None,False,None,"Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
",0.0,True,False,False,False,torch.float16,False,0,"[128001, 128008, 128009]",None,0,True,False,1,IntervalStrategy.STEPS,False,None,None,None,None,None,True,auto,False,O1,[],"{'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}",0,None,False,16,False,None,None,False,auto,128,silu,3072,False,None,False,HubStrategy.EVERY_SAVE,None,"{0: 'LABEL_0', 1: 'LABEL_1'}",False,[],False,False,False,0.02,8192,False,False,False,"{'LABEL_0': 0, 'LABEL_1': 1}",None,0.0,0.002,length,1.0,False,True,0,None,passive,warning,True,outputs/runs/Nov17_14-29-05_cce60367e48b,False,True,1,IntervalStrategy.STEPS,16,0.1,{},SchedulerType.LINEAR,1.0,20,131072,2048,-1,None,0,False,unsloth/Llama-3.2-3B-Instruct-bnb-4bit,llama,,None,False,0,24,1,1,28,8,1,5,OptimizerNames.ADAMW_8BIT,None,None,False,outputs,False,False,False,<|finetune_right_pad_id|>,128004,left,-1,8,3,None,None,False,None,1,None,{},False,None,None,None,"{'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': None, 'llm_int8_threshold': 6.0, 'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'bitsandbytes'}",128,3407,last,False,True,1.0,"['mlflow', 'tensorboard', 'wandb']",False,None,True,False,1e-05,"{'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}",500000.0,outputs,False,False,True,500,IntervalStrategy.EPOCH,None,3407,None,True,None,None,None,1.0,None,False,False,True,None,50,1.0,False,None,None,float16,None,None,False,False,None,4.46.2,1.0,2024.11.7,False,True,False,none,False,False,False,False,False,128256,0.0,10,0.01,4.760180995475113,0.8482415080070496,19.2619,4.309,0.571,0.024753376841545105,0.000036363636363636364,0.8432,,,,,,0.8432,0.8482415080070496,Llama8B
2024-11-17 15:11:27,1.2h,0e7abbf7ef274779bbc7fcab3f5349ee,nebulous-stag-13,LOCAL,/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py,root,FINISHED,PreTrainedTokenizerFast,cuda:0,True,1,unsloth/Llama-3.2-3B-Instruct-bnb-4bit,"AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False)",False,0.9,0.999,1e-08,False,['LlamaForCausalLM'],False,0.0,False,False,None,False,None,False,False,128000,0,None,None,False,0,False,True,None,None,None,None,None,1800,[],None,None,None,False,None,"Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
",0.0,True,False,False,False,torch.float16,False,0,"[128001, 128008, 128009]",None,0,True,False,1,IntervalStrategy.STEPS,False,None,None,None,None,None,True,auto,False,O1,[],"{'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}",0,None,False,16,False,None,None,False,auto,128,silu,3072,False,None,False,HubStrategy.EVERY_SAVE,None,"{0: 'LABEL_0', 1: 'LABEL_1'}",False,[],False,False,False,0.02,8192,False,False,False,"{'LABEL_0': 0, 'LABEL_1': 1}",None,0.0,0.002,length,1.0,False,True,0,None,passive,warning,True,outputs/runs/Nov17_13-11-32_cce60367e48b,False,True,1,IntervalStrategy.STEPS,16,0.1,{},SchedulerType.LINEAR,1.0,20,131072,2048,-1,None,0,False,unsloth/Llama-3.2-3B-Instruct-bnb-4bit,llama,,None,False,0,24,1,1,28,8,1,5,OptimizerNames.ADAMW_8BIT,None,None,False,outputs,False,False,False,<|finetune_right_pad_id|>,128004,left,-1,8,2,None,None,False,None,1,None,{},False,None,None,None,"{'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': None, 'llm_int8_threshold': 6.0, 'load_in_4bit': True, 'load_in_8bit': False, 'quant_method': 'bitsandbytes'}",128,3407,last,False,True,1.0,"['mlflow', 'tensorboard', 'wandb']",False,None,True,False,1e-05,"{'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}",500000.0,outputs,False,False,True,500,IntervalStrategy.EPOCH,None,3407,None,True,None,None,None,1.0,None,False,False,True,None,50,1.0,False,None,None,float16,None,None,False,False,None,4.46.2,1.0,2024.11.7,False,True,False,none,False,False,False,False,False,128256,0.0,10,0.01,4.8942598187311175,0.7634868621826172,21.1741,3.92,0.52,0.033883847296237946,0,0.7357,28572088275701760,0.9068499028682708,4269.0523,0.775,0.023,0.7357,0.7634868621826172,Llama8B
