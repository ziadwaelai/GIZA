{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9931323,"sourceType":"datasetVersion","datasetId":6104747}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n!pip install torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n!pip install mlflow pyngrok","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 #2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = getattr(torch, \"float16\") # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:14.136165Z","iopub.execute_input":"2024-11-17T14:26:14.136539Z","iopub.status.idle":"2024-11-17T14:26:29.111802Z","shell.execute_reply.started":"2024-11-17T14:26:14.136496Z","shell.execute_reply":"2024-11-17T14:26:29.110298Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"model_id=\"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:29.114443Z","iopub.execute_input":"2024-11-17T14:26:29.114813Z","iopub.status.idle":"2024-11-17T14:26:29.119854Z","shell.execute_reply.started":"2024-11-17T14:26:29.114773Z","shell.execute_reply":"2024-11-17T14:26:29.118958Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = model_id,\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:29.121147Z","iopub.execute_input":"2024-11-17T14:26:29.121770Z","iopub.status.idle":"2024-11-17T14:26:39.874773Z","shell.execute_reply.started":"2024-11-17T14:26:29.121726Z","shell.execute_reply":"2024-11-17T14:26:39.873646Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.2.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token\n\ntrain_prompt = \"\"\"Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\n\n### DESCRIPTION:\n{}\n\n### RESPONSE:\n{}\"\"\"\n\n\ndef formatting_prompts_func(examples):\n\n    inputs       = examples[\"series_description\"]\n    outputs      = examples[\"algorithm\"]\n    texts = []\n    for input, output in zip( inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = train_prompt.format( input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:46.352526Z","iopub.execute_input":"2024-11-17T14:26:46.353291Z","iopub.status.idle":"2024-11-17T14:26:46.359833Z","shell.execute_reply.started":"2024-11-17T14:26:46.353240Z","shell.execute_reply":"2024-11-17T14:26:46.358821Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('csv', data_files='/kaggle/input/regression-univariate-train/Regression_Univariate_train.csv', split='train')\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:47.193962Z","iopub.execute_input":"2024-11-17T14:26:47.194631Z","iopub.status.idle":"2024-11-17T14:26:47.364418Z","shell.execute_reply.started":"2024-11-17T14:26:47.194578Z","shell.execute_reply":"2024-11-17T14:26:47.363526Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['dataset_name', 'series_description', 'algorithm', 'hyperparameters'],\n    num_rows: 828\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Split the dataset into train and valid sets\ntrain_valid_test_split = dataset.train_test_split(test_size=0.2, seed=42)  # 80% train + 20% temp\nvalid_test_split = train_valid_test_split['test'].train_test_split(test_size=0.5, seed=42)  # 10% each for validation and test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:48.319741Z","iopub.execute_input":"2024-11-17T14:26:48.320183Z","iopub.status.idle":"2024-11-17T14:26:48.340682Z","shell.execute_reply.started":"2024-11-17T14:26:48.320142Z","shell.execute_reply":"2024-11-17T14:26:48.339339Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_dataset = train_valid_test_split['train']   # 80% train\nvalid_dataset = valid_test_split['train']         # 10% validation\ntest_dataset = valid_test_split['test']           # 10% test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:49.074248Z","iopub.execute_input":"2024-11-17T14:26:49.075177Z","iopub.status.idle":"2024-11-17T14:26:49.080096Z","shell.execute_reply.started":"2024-11-17T14:26:49.075132Z","shell.execute_reply":"2024-11-17T14:26:49.078992Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset = train_dataset.map(formatting_prompts_func, batched = True)\ntrain_dataset['text'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:49.795928Z","iopub.execute_input":"2024-11-17T14:26:49.796326Z","iopub.status.idle":"2024-11-17T14:26:49.854920Z","shell.execute_reply.started":"2024-11-17T14:26:49.796287Z","shell.execute_reply":"2024-11-17T14:26:49.854124Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/662 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acd64f9d8aab4d1190695e02dcaa77bb"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 144 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 480 minutes, minimum value of -1.2289464767798075, maximum value of 1.21550900898212, median value of 0.0, mean value of -0.0007690196408217143, and average standard deviation of 0.27668995423649856 for the 10 percentiles. The series is detected as stationary using dickey fuller test.The series has 7 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 7 lags ranges from 0.7904835601016195 for the lag number 1 to -0.603704007620162 for the lag number 9. There exist 3 insignificant lags at these indices 2,3,7 between the first and the last significant ones. The series looks to be a additive time-series with a linear trend. There are 1 seasonality components detected in this series represented as sinusoidal waves with periods 20.The series exhibits a skewness value of 0.034566016619103766 and a kurtosis value of 1.4096301230718031. The Fractal dimension analysis yields a value of -0.3197538015832301, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE:\\nSVR<|eot_id|>'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"valid_dataset = valid_dataset.map(formatting_prompts_func, batched = True)\nvalid_dataset['text'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:52.495804Z","iopub.execute_input":"2024-11-17T14:26:52.496606Z","iopub.status.idle":"2024-11-17T14:26:52.534390Z","shell.execute_reply.started":"2024-11-17T14:26:52.496569Z","shell.execute_reply":"2024-11-17T14:26:52.533482Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/83 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76f4c7825d447d8aac48bb4bacedbe4"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 206 samples with a missing values percentage of 0.0% imputed using FBProphet model and 8.25242718446602% detected outliers. The target series has a sampling rate of 1440 minutes, minimum value of 750.0, maximum value of 3000.0, median value of 1500.0, mean value of 1625.4901960784314, and average standard deviation of 0.11924729621778932 for the 10 percentiles. The series is detected as non-stationary using dickey fuller testand it turns into a stationary series using first order differencing. The series has only 1 significant laf observed using the partial autocorrelation function (pACF) with value 0.9795278581343962.The series looks to be a multiplicative time-series with a logistic trend. There are 2 seasonality components detected in this series represented as sinusoidal waves with periods 206,68.The series exhibits a skewness value of 0.9341688170988668 and a kurtosis value of 0.284080665836957. The Fractal dimension analysis yields a value of -0.06723616815792989, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE:\\nLassoRegressor<|eot_id|>'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"tokenizer_config= {\n    \"Tokenizer\": tokenizer.__class__.__name__,\n    \"padding_side\": tokenizer.padding_side,\n    \"pad_token\": tokenizer.pad_token\n}\nmodel_params ={\n    \"model_name\": model_id,\n    \"max_seq_length\": max_seq_length,\n    \"dtype\": dtype,\n    \"load_in_4bit\": load_in_4bit,   \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:53.856052Z","iopub.execute_input":"2024-11-17T14:26:53.856465Z","iopub.status.idle":"2024-11-17T14:26:53.862265Z","shell.execute_reply.started":"2024-11-17T14:26:53.856426Z","shell.execute_reply":"2024-11-17T14:26:53.861177Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from pyngrok import ngrok\nngrok.set_auth_token(\"2oySnSA3Uw7Lt3MuzrBoDynO5vG_u1X7wvXRbvPvEBoo3k3U\")\nget_ipython().system_raw(\"mlflow ui --port 5000 &\")\npublic_url = ngrok.connect(5000, \"http\")\nprint(f\"MLflow UI accessible at: {public_url}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:26:56.258641Z","iopub.execute_input":"2024-11-17T14:26:56.259062Z","iopub.status.idle":"2024-11-17T14:26:56.907130Z","shell.execute_reply.started":"2024-11-17T14:26:56.259025Z","shell.execute_reply":"2024-11-17T14:26:56.906022Z"}},"outputs":[{"name":"stdout","text":"MLflow UI accessible at: NgrokTunnel: \"https://78d5-35-226-137-11.ngrok-free.app\" -> \"http://localhost:5000\"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import mlflow\n# Set MLflow's tracking URI and experiment\nmlflow.set_tracking_uri(\"https://78d5-35-226-137-11.ngrok-free.app\")\nmlflow.set_experiment(\"unsloth_Llama_3.1_8B_Regression_Univariate\")\nmlflow.pytorch.autolog(disable=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:28:22.469541Z","iopub.execute_input":"2024-11-17T14:28:22.470488Z","iopub.status.idle":"2024-11-17T14:28:22.910128Z","shell.execute_reply.started":"2024-11-17T14:28:22.470445Z","shell.execute_reply":"2024-11-17T14:28:22.909163Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import TrainerCallback\nclass MLFlowLoggingCallback(TrainerCallback):\n    def __init__(self):\n        self.training_loss = []\n        self.eval_loss = []\n\n    def on_train_begin(self, args, state, control, **kwargs):\n        # Initialize logging at the start of training\n        print(\"Training started.\")\n\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        # Log training and evaluation losses\n        if 'loss' in logs:\n            self.training_loss.append(logs['loss'])\n            mlflow.log_metric(\"training_loss\", logs['loss'], step=state.global_step)\n\n        if 'eval_loss' in logs:\n            self.eval_loss.append(logs['eval_loss'])\n            mlflow.log_metric(\"validation_loss\", logs['eval_loss'], step=state.global_step)\n\n        if 'eval_f1' in logs:\n            mlflow.log_metric(\"validation_f1\", logs['eval_f1'], step=state.global_step)\n\n    def on_train_end(self, args, state, control, **kwargs):\n        # Log final results at the end of training\n        print(\"Training completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:28:26.622187Z","iopub.execute_input":"2024-11-17T14:28:26.623689Z","iopub.status.idle":"2024-11-17T14:28:26.631933Z","shell.execute_reply.started":"2024-11-17T14:28:26.623645Z","shell.execute_reply":"2024-11-17T14:28:26.631016Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\ndef configure_and_train_model(\n    r=128,\n    lora_alpha=16,\n    lora_dropout=0.1,\n    use_gradient_checkpointing=\"none\",\n    random_state=2048,\n    use_rslora=False,\n    loftq_config=None,\n    train_dataset=None,\n    valid_dataset=None,\n    batch_size=2,\n    grad_accum_steps=16,\n    warmup_steps=5,\n    max_steps=-1,\n    learning_rate=2e-3,\n    weight_decay=0.01,\n    lr_scheduler_type=\"linear\",\n    output_dir=\"outputs\",\n    epochs = 3\n):\n    global model\n    # Load model and tokenizer with specified settings\n    lora_config = {\n        \"r\": r,\n        \"lora_alpha\": lora_alpha,\n        \"lora_dropout\": lora_dropout,\n        \"use_gradient_checkpointing\": use_gradient_checkpointing,\n        \"random_state\": random_state,\n        \"use_rslora\": use_rslora,\n        \"loftq_config\": loftq_config,\n    }\n    with mlflow.start_run():\n      mlflow.set_tag(\"model_name\", \"Llama8B\")\n      # Format datasets with EOS token\n      train_dataset = train_dataset.map(\n            lambda batch: formatting_prompts_func(batch),\n            batched=True\n        )\n      valid_dataset = valid_dataset.map(\n            lambda batch: formatting_prompts_func(batch),\n            batched=True\n        )\n\n      # Configure PEFT model\n      model = FastLanguageModel.get_peft_model(\n          model,\n          r=r,\n          target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n          lora_alpha=lora_alpha,\n          lora_dropout=lora_dropout,\n          bias=\"none\",\n          use_gradient_checkpointing=use_gradient_checkpointing,\n          random_state=random_state,\n          use_rslora=use_rslora,\n          loftq_config=loftq_config\n      )\n    \n      # Training arguments\n      training_args = TrainingArguments(\n          num_train_epochs=epochs,\n          per_device_train_batch_size=batch_size,\n          gradient_accumulation_steps=grad_accum_steps,\n          warmup_steps=warmup_steps,\n          max_steps=max_steps,\n          learning_rate=learning_rate,\n          fp16=not is_bfloat16_supported(),\n          bf16=is_bfloat16_supported(),\n          logging_steps=1,\n          optim=\"adamw_8bit\",\n          weight_decay=weight_decay,\n          lr_scheduler_type=lr_scheduler_type,\n          seed=random_state,\n          output_dir=output_dir,\n          eval_strategy=\"steps\",\n          save_strategy=\"epoch\"\n      )\n      mlflow.log_params(vars(training_args))\n      mlflow.log_params(model_params)\n      mlflow.log_params(tokenizer_config)\n      mlflow.log_params(lora_config)\n      # Trainer setup\n      trainer = SFTTrainer(\n          model=model,\n          tokenizer=tokenizer,\n          train_dataset=train_dataset,\n          eval_dataset=valid_dataset,\n          dataset_text_field=\"text\",\n          max_seq_length=2048,\n          dataset_num_proc=2,\n          packing=False,\n          args=training_args\n          )\n      # Initialize the callback\n      mlflow_callback = MLFlowLoggingCallback()\n\n      # Train the model with the callback\n      trainer.add_callback(mlflow_callback)\n      # Train the model\n      trainer.train()\n      return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:28:37.039673Z","iopub.execute_input":"2024-11-17T14:28:37.040142Z","iopub.status.idle":"2024-11-17T14:28:37.056644Z","shell.execute_reply.started":"2024-11-17T14:28:37.040099Z","shell.execute_reply":"2024-11-17T14:28:37.055600Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:27:00.993162Z","iopub.execute_input":"2024-11-17T14:27:00.993688Z","iopub.status.idle":"2024-11-17T14:27:01.007813Z","shell.execute_reply.started":"2024-11-17T14:27:00.993635Z","shell.execute_reply":"2024-11-17T14:27:01.006692Z"}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n2.543 GB of memory reserved.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import time\nstart= time.time()\n# Configure and train the model with specified parameters\nmodel = configure_and_train_model(\n    r=128,                 # LoRA rank parameter\n    lora_alpha=16,        # Scaling factor for LoRA layers\n    lora_dropout=0.1,       # Set dropout to 0 (optimized)\n    use_gradient_checkpointing=\"none\",  # Memory optimization\n    random_state=3407,    # Seed for reproducibility\n    use_rslora=False,     # Disable rank-stabilized LoRA\n    loftq_config=None,    # Leave as None for default\n    train_dataset=train_dataset,\n    valid_dataset=valid_dataset,\n    batch_size=3,         # Set batch size for training\n    grad_accum_steps=16,   # Gradient accumulation steps\n    warmup_steps=10,       # Warmup steps for learning rate scheduler\n    max_steps=-1,         # Total steps for quick testing\n    learning_rate=2e-3,   # Learning rate\n    weight_decay=0.01,    # Weight decay for optimizer\n    lr_scheduler_type=\"linear\",  # Learning rate scheduler type\n    output_dir=\"outputs\",  # Directory for saving results\n    epochs = 5\n)\nprint((time.time()-start)/60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T14:29:00.535090Z","iopub.execute_input":"2024-11-17T14:29:00.535997Z","iopub.status.idle":"2024-11-17T15:19:35.151496Z","shell.execute_reply.started":"2024-11-17T14:29:00.535954Z","shell.execute_reply":"2024-11-17T15:19:35.150538Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/662 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44237832b874c1caf2f323f3a7febd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/83 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67a7814a275e402abfc68125c6c70c21"}},"metadata":{}},{"name":"stderr","text":"Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\nUnsloth will patch all other layers, except LoRA matrices, causing a performance hit.\nUnsloth 2024.11.7 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/662 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad3bc82ae1144ad28e0f1deb2894a0f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/83 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3456d31f21415e9318fcbf5a8398f1"}},"metadata":{}},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 662 | Num Epochs = 5\nO^O/ \\_/ \\    Batch size per device = 3 | Gradient Accumulation steps = 16\n\\        /    Total batch size = 48 | Total steps = 65\n \"-____-\"     Number of trainable parameters = 194,510,848\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mziadwael142\u001b[0m (\u001b[33mziadwael142-giza-systems\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111345200000263, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11fd2d63e5814b8599811af3d8003414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241117_142915-q51i0g89</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ziadwael142-giza-systems/huggingface/runs/q51i0g89' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/ziadwael142-giza-systems/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ziadwael142-giza-systems/huggingface' target=\"_blank\">https://wandb.ai/ziadwael142-giza-systems/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ziadwael142-giza-systems/huggingface/runs/q51i0g89' target=\"_blank\">https://wandb.ai/ziadwael142-giza-systems/huggingface/runs/q51i0g89</a>"},"metadata":{}},{"name":"stdout","text":"Training started.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [65/65 49:45, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.188000</td>\n      <td>3.185171</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.192500</td>\n      <td>3.026662</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.049800</td>\n      <td>2.691400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.718200</td>\n      <td>2.194016</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.213700</td>\n      <td>1.684431</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.708800</td>\n      <td>1.438652</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.476100</td>\n      <td>1.297304</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.304500</td>\n      <td>1.132477</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.141300</td>\n      <td>1.023324</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.069700</td>\n      <td>0.970793</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.984900</td>\n      <td>0.951199</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.977100</td>\n      <td>0.933737</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.921800</td>\n      <td>0.924610</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.530500</td>\n      <td>0.932627</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.918200</td>\n      <td>0.912293</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.932600</td>\n      <td>0.902027</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.915700</td>\n      <td>0.898832</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.905500</td>\n      <td>0.890322</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.916100</td>\n      <td>0.890837</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.911300</td>\n      <td>0.891892</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.912800</td>\n      <td>0.881210</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.885300</td>\n      <td>0.881677</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.909800</td>\n      <td>0.880117</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.903400</td>\n      <td>0.880388</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.887500</td>\n      <td>0.876623</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.904200</td>\n      <td>0.875574</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.459000</td>\n      <td>0.872929</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.874600</td>\n      <td>0.872478</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.917100</td>\n      <td>0.872711</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.882300</td>\n      <td>0.872447</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.875600</td>\n      <td>0.870708</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.875200</td>\n      <td>0.866881</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.875700</td>\n      <td>0.865746</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.860900</td>\n      <td>0.864797</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.851400</td>\n      <td>0.864220</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.864100</td>\n      <td>0.864026</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.876500</td>\n      <td>0.863324</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.884700</td>\n      <td>0.861897</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.863000</td>\n      <td>0.860243</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.256800</td>\n      <td>0.859474</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.070100</td>\n      <td>0.857990</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.853100</td>\n      <td>0.857723</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.870700</td>\n      <td>0.859080</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.821600</td>\n      <td>0.859586</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.843300</td>\n      <td>0.857641</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.836900</td>\n      <td>0.855533</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.874100</td>\n      <td>0.853866</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.872900</td>\n      <td>0.853593</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.856400</td>\n      <td>0.853110</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.842100</td>\n      <td>0.852016</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.857000</td>\n      <td>0.851673</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.860000</td>\n      <td>0.852350</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.843600</td>\n      <td>0.853320</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.380900</td>\n      <td>0.852622</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.851700</td>\n      <td>0.851895</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.866800</td>\n      <td>0.850612</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.828700</td>\n      <td>0.849607</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.841000</td>\n      <td>0.849121</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.862900</td>\n      <td>0.848821</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.849400</td>\n      <td>0.848456</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.814400</td>\n      <td>0.848269</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.852500</td>\n      <td>0.848190</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.846900</td>\n      <td>0.848242</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.843200</td>\n      <td>0.848291</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.828900</td>\n      <td>0.848294</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"2024/11/17 14:30:15 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id e36e01a8e14a4fd6b272143744149d9c: Failed to log run data: Exception: API request to https://78d5-35-226-137-11.ngrok-free.app/api/2.0/mlflow/runs/log-batch failed with exception HTTPSConnectionPool(host='78d5-35-226-137-11.ngrok-free.app', port=443): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError('too many 500 error responses'))\n2024/11/17 14:30:16 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id e36e01a8e14a4fd6b272143744149d9c: Failed to log run data: Exception: API request to https://78d5-35-226-137-11.ngrok-free.app/api/2.0/mlflow/runs/log-batch failed with exception HTTPSConnectionPool(host='78d5-35-226-137-11.ngrok-free.app', port=443): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError('too many 500 error responses'))\n","output_type":"stream"},{"name":"stdout","text":"Training completed.\n","output_type":"stream"},{"name":"stderr","text":"2024/11/17 15:19:35 INFO mlflow.tracking._tracking_service.client: 🏃 View run illustrious-colt-932 at: https://78d5-35-226-137-11.ngrok-free.app/#/experiments/314000315323789333/runs/e36e01a8e14a4fd6b272143744149d9c.\n2024/11/17 15:19:35 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://78d5-35-226-137-11.ngrok-free.app/#/experiments/314000315323789333.\n","output_type":"stream"},{"name":"stdout","text":"50.57678665717443\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:19:35.322513Z","iopub.execute_input":"2024-11-17T15:19:35.322850Z","iopub.status.idle":"2024-11-17T15:19:35.336933Z","shell.execute_reply.started":"2024-11-17T15:19:35.322813Z","shell.execute_reply":"2024-11-17T15:19:35.335894Z"}},"outputs":[{"name":"stdout","text":"Peak reserved memory = 13.387 GB.\nPeak reserved memory for training = 10.844 GB.\nPeak reserved memory % of max memory = 90.815 %.\nPeak reserved memory for training % of max memory = 73.564 %.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"test_prompt = \"\"\"Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\n\n### DESCRIPTION:\n{}\n\n### RESPONSE:\"\"\"\n\n\ndef formatting_test_prompts_func(examples):\n    global tokenizer\n\n    inputs = examples[\"series_description\"]\n    texts = []\n    for input in  inputs:\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = test_prompt.format( input)\n        texts.append(text)\n    return { \"text\" : texts }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:19:35.338642Z","iopub.execute_input":"2024-11-17T15:19:35.339050Z","iopub.status.idle":"2024-11-17T15:19:35.569587Z","shell.execute_reply.started":"2024-11-17T15:19:35.339002Z","shell.execute_reply":"2024-11-17T15:19:35.568683Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"test_dataset = test_dataset.map(formatting_test_prompts_func, batched = True)\ntest_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:19:35.571644Z","iopub.execute_input":"2024-11-17T15:19:35.571938Z","iopub.status.idle":"2024-11-17T15:19:36.739900Z","shell.execute_reply.started":"2024-11-17T15:19:35.571906Z","shell.execute_reply":"2024-11-17T15:19:36.738981Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['dataset_name', 'series_description', 'algorithm', 'hyperparameters', 'text'],\n    num_rows: 83\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# alpaca_prompt = Copied from above\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[test_dataset['text'][0]], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:19:36.741057Z","iopub.execute_input":"2024-11-17T15:19:36.741364Z","iopub.status.idle":"2024-11-17T15:19:38.480325Z","shell.execute_reply.started":"2024-11-17T15:19:36.741330Z","shell.execute_reply":"2024-11-17T15:19:38.479357Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['<|begin_of_text|>Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 48 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 1440 minutes, minimum value of -1.0577518085465023, maximum value of 0.5039540640878073, median value of -0.5925601507310199, mean value of -0.49076897775897593, and average standard deviation of 0.21373626312059368 for the 10 percentiles. The series is detected as non-stationary using dickey fuller testand it turns into a stationary series using first order differencing. The series has 6 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 6 lags ranges from 0.6091821079108509 for the lag number 1 to 0.3608509812237311 for the lag number 7. There exist 1 insignificant lags at these indices 4 between the first and the last significant ones. The series looks to be a multiplicative time-series with a logistic trend. There are no seasonality components detected in the seriesThe series exhibits a skewness value of 0.6670990699653278 and a kurtosis value of 0.47278337091329936. The Fractal dimension analysis yields a value of -0.4583557992511385, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE: ElasticNetRegressor<|eot_id|>']"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"inputs = tokenizer(\n[test_dataset['text'][1]], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 5, use_cache = True)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:19:38.481699Z","iopub.execute_input":"2024-11-17T15:19:38.482121Z","iopub.status.idle":"2024-11-17T15:19:39.114210Z","shell.execute_reply.started":"2024-11-17T15:19:38.482073Z","shell.execute_reply":"2024-11-17T15:19:39.113343Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['<|begin_of_text|>Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 81 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 44640 minutes, minimum value of 3523.548387096774, maximum value of 6434.0, median value of 4978.387096774193, mean value of 4995.464271746457, and average standard deviation of 0.06947531163920204 for the 10 percentiles. The series is detected as stationary using dickey fuller test.The series has 7 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 7 lags ranges from 0.9375534431746181 for the lag number 1 to 0.2340147204900702 for the lag number 7.There are no insignificant lags in between the first and the last significant ones.The series looks to be a multiplicative time-series with a linear trend. There are 1 seasonality components detected in this series represented as sinusoidal waves with periods 27.The series exhibits a skewness value of 0.018459508790673103 and a kurtosis value of 1.0220489598846814. The Fractal dimension analysis yields a value of -0.07028093361365781, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE: ExtraTreesRegressor<|eot_id|>']"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"test_responses=[]\n# get all test data inference result\nfor test_prompt in test_dataset['text']:\n  inputs= tokenizer(\n  [test_prompt], return_tensors = \"pt\").to(\"cuda\")\n\n  outputs = model.generate(**inputs, max_new_tokens = 5, use_cache = True)\n  test_responses.append(tokenizer.batch_decode(outputs))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:19:39.115458Z","iopub.execute_input":"2024-11-17T15:19:39.115834Z","iopub.status.idle":"2024-11-17T15:20:31.798689Z","shell.execute_reply.started":"2024-11-17T15:19:39.115784Z","shell.execute_reply":"2024-11-17T15:20:31.797420Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"df = test_dataset.to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:20:43.531675Z","iopub.execute_input":"2024-11-17T15:20:43.532399Z","iopub.status.idle":"2024-11-17T15:20:43.539408Z","shell.execute_reply.started":"2024-11-17T15:20:43.532350Z","shell.execute_reply":"2024-11-17T15:20:43.538557Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"df['model_responses']= test_responses\ndf.to_csv('test_model_result_unsloth.csv', index=False)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:20:44.208295Z","iopub.execute_input":"2024-11-17T15:20:44.209306Z","iopub.status.idle":"2024-11-17T15:20:44.250558Z","shell.execute_reply.started":"2024-11-17T15:20:44.209254Z","shell.execute_reply":"2024-11-17T15:20:44.249665Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"        dataset_name                                 series_description  \\\n0             33.csv  A univariate time-series dataset  consists of ...   \n1   M36312_train.csv  A univariate time-series dataset  consists of ...   \n2            134.csv  A univariate time-series dataset  consists of ...   \n3            222.csv  A univariate time-series dataset  consists of ...   \n4             75.csv  A univariate time-series dataset  consists of ...   \n..               ...                                                ...   \n78    W221_train.csv  A univariate time-series dataset  consists of ...   \n79           449.csv  A univariate time-series dataset  consists of ...   \n80           395.csv  A univariate time-series dataset  consists of ...   \n81            11.csv  A univariate time-series dataset  consists of ...   \n82  M37780_train.csv  A univariate time-series dataset  consists of ...   \n\n                   algorithm  \\\n0   GaussianProcessRegressor   \n1   GaussianProcessRegressor   \n2   GaussianProcessRegressor   \n3        ElasticNetRegressor   \n4           XGBoostRegressor   \n..                       ...   \n78       ElasticNetRegressor   \n79          XGBoostRegressor   \n80         AdaboostRegressor   \n81         AdaboostRegressor   \n82            LassoRegressor   \n\n                                      hyperparameters  \\\n0   {'alpha': 0.01, 'kernel': 1**2 * RBF(length_sc...   \n1   {'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...   \n2   {'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...   \n3   {'l1_ratio': 0.7666666666666666, 'random_state...   \n4   {'colsample_bytree': 0.5, 'gamma': 0.9, 'learn...   \n..                                                ...   \n78  {'l1_ratio': 1.0, 'random_state': 42, 'selecti...   \n79  {'colsample_bytree': 1.0, 'gamma': 3.996320950...   \n80  {'estimator': DecisionTreeRegressor(max_depth=...   \n81  {'estimator': DecisionTreeRegressor(max_depth=...   \n82  {'alpha': 0.24381437457499952, 'random_state':...   \n\n                                                 text  \\\n0   Below is a description for a time series data....   \n1   Below is a description for a time series data....   \n2   Below is a description for a time series data....   \n3   Below is a description for a time series data....   \n4   Below is a description for a time series data....   \n..                                                ...   \n78  Below is a description for a time series data....   \n79  Below is a description for a time series data....   \n80  Below is a description for a time series data....   \n81  Below is a description for a time series data....   \n82  Below is a description for a time series data....   \n\n                                      model_responses  \n0   [<|begin_of_text|>Below is a description for a...  \n1   [<|begin_of_text|>Below is a description for a...  \n2   [<|begin_of_text|>Below is a description for a...  \n3   [<|begin_of_text|>Below is a description for a...  \n4   [<|begin_of_text|>Below is a description for a...  \n..                                                ...  \n78  [<|begin_of_text|>Below is a description for a...  \n79  [<|begin_of_text|>Below is a description for a...  \n80  [<|begin_of_text|>Below is a description for a...  \n81  [<|begin_of_text|>Below is a description for a...  \n82  [<|begin_of_text|>Below is a description for a...  \n\n[83 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_name</th>\n      <th>series_description</th>\n      <th>algorithm</th>\n      <th>hyperparameters</th>\n      <th>text</th>\n      <th>model_responses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>GaussianProcessRegressor</td>\n      <td>{'alpha': 0.01, 'kernel': 1**2 * RBF(length_sc...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M36312_train.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>GaussianProcessRegressor</td>\n      <td>{'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>134.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>GaussianProcessRegressor</td>\n      <td>{'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>222.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>ElasticNetRegressor</td>\n      <td>{'l1_ratio': 0.7666666666666666, 'random_state...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>XGBoostRegressor</td>\n      <td>{'colsample_bytree': 0.5, 'gamma': 0.9, 'learn...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>W221_train.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>ElasticNetRegressor</td>\n      <td>{'l1_ratio': 1.0, 'random_state': 42, 'selecti...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>449.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>XGBoostRegressor</td>\n      <td>{'colsample_bytree': 1.0, 'gamma': 3.996320950...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>395.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>AdaboostRegressor</td>\n      <td>{'estimator': DecisionTreeRegressor(max_depth=...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>11.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>AdaboostRegressor</td>\n      <td>{'estimator': DecisionTreeRegressor(max_depth=...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>M37780_train.csv</td>\n      <td>A univariate time-series dataset  consists of ...</td>\n      <td>LassoRegressor</td>\n      <td>{'alpha': 0.24381437457499952, 'random_state':...</td>\n      <td>Below is a description for a time series data....</td>\n      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>83 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"test_responses[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:20:48.608653Z","iopub.execute_input":"2024-11-17T15:20:48.609368Z","iopub.status.idle":"2024-11-17T15:20:48.616952Z","shell.execute_reply.started":"2024-11-17T15:20:48.609323Z","shell.execute_reply":"2024-11-17T15:20:48.616006Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"['<|begin_of_text|>Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 81 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 44640 minutes, minimum value of 3523.548387096774, maximum value of 6434.0, median value of 4978.387096774193, mean value of 4995.464271746457, and average standard deviation of 0.06947531163920204 for the 10 percentiles. The series is detected as stationary using dickey fuller test.The series has 7 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 7 lags ranges from 0.9375534431746181 for the lag number 1 to 0.2340147204900702 for the lag number 7.There are no insignificant lags in between the first and the last significant ones.The series looks to be a multiplicative time-series with a linear trend. There are 1 seasonality components detected in this series represented as sinusoidal waves with periods 27.The series exhibits a skewness value of 0.018459508790673103 and a kurtosis value of 1.0220489598846814. The Fractal dimension analysis yields a value of -0.07028093361365781, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE: AdaboostRegressor<|eot_id|>']"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"predictions = []\n\nfor response in test_responses:\n    try:\n        prediction = response[0].split('\\n\\n### RESPONSE:')[1].split('</s>')[0].strip()        \n        clean_prediction = prediction.split('<|eot_id|>')[0].strip()        \n        predictions.append(clean_prediction)\n    except IndexError:\n        predictions.append(\"Invalid response\")\n\npredictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:20:52.860459Z","iopub.execute_input":"2024-11-17T15:20:52.861417Z","iopub.status.idle":"2024-11-17T15:20:52.872381Z","shell.execute_reply.started":"2024-11-17T15:20:52.861367Z","shell.execute_reply":"2024-11-17T15:20:52.871348Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"['GaussianProcessRegressor',\n 'AdaboostRegressor',\n 'ExtraTreesRegressor',\n 'ElasticNetRegressor',\n 'AdaboostRegressor',\n 'AdaboostRegressor',\n 'GaussianProcessRegressor',\n 'ExtraTreesRegressor',\n 'SVR',\n 'AdaboostRegressor',\n 'SVR',\n 'AdaboostRegressor',\n 'AdaboostRegressor',\n 'ExtraTreesRegressor',\n 'ElasticNetRegressor',\n 'ExtraTreesRegressor',\n 'AdaboostRegressor',\n 'ElasticNetRegressor',\n 'SVR',\n 'SVR',\n 'ExtraTreesRegressor',\n 'SVR',\n 'AdaboostRegressor',\n 'AdaboostRegressor',\n 'SVR',\n 'SVR',\n 'ElasticNetRegressor',\n 'AdaboostRegressor',\n 'GaussianProcessRegressor',\n 'SVR',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'GaussianProcessRegressor',\n 'AdaboostRegressor',\n 'GaussianProcessRegressor',\n 'SVR',\n 'AdaboostRegressor',\n 'GaussianProcessRegressor',\n 'SVR',\n 'AdaboostRegressor',\n 'SVR',\n 'AdaboostRegressor',\n 'ElasticNetRegressor',\n 'ExtraTreesRegressor',\n 'ExtraTreesRegressor',\n 'ElasticNetRegressor',\n 'ExtraTreesRegressor',\n 'AdaboostRegressor',\n 'AdaboostRegressor',\n 'AdaboostRegressor',\n 'SVR',\n 'ElasticNetRegressor',\n 'AdaboostRegressor',\n 'ExtraTreesRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'AdaboostRegressor',\n 'AdaboostRegressor',\n 'GaussianProcessRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'AdaboostRegressor',\n 'ElasticNetRegressor',\n 'AdaboostRegressor',\n 'AdaboostRegressor',\n 'SVR',\n 'AdaboostRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'ElasticNetRegressor',\n 'GaussianProcessRegressor',\n 'ElasticNetRegressor',\n 'ExtraTreesRegressor',\n 'SVR',\n 'ElasticNetRegressor',\n 'SVR',\n 'SVR',\n 'AdaboostRegressor']"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"len(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:21:01.266331Z","iopub.execute_input":"2024-11-17T15:21:01.266766Z","iopub.status.idle":"2024-11-17T15:21:01.274440Z","shell.execute_reply.started":"2024-11-17T15:21:01.266726Z","shell.execute_reply":"2024-11-17T15:21:01.273357Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"83"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"actual_data= df['algorithm']\nlen(actual_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:21:20.917532Z","iopub.execute_input":"2024-11-17T15:21:20.918302Z","iopub.status.idle":"2024-11-17T15:21:20.925429Z","shell.execute_reply.started":"2024-11-17T15:21:20.918258Z","shell.execute_reply":"2024-11-17T15:21:20.924502Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"83"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"actual_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:21:22.320465Z","iopub.execute_input":"2024-11-17T15:21:22.321131Z","iopub.status.idle":"2024-11-17T15:21:22.330219Z","shell.execute_reply.started":"2024-11-17T15:21:22.321089Z","shell.execute_reply":"2024-11-17T15:21:22.329319Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"0     GaussianProcessRegressor\n1     GaussianProcessRegressor\n2     GaussianProcessRegressor\n3          ElasticNetRegressor\n4             XGBoostRegressor\n                ...           \n78         ElasticNetRegressor\n79            XGBoostRegressor\n80           AdaboostRegressor\n81           AdaboostRegressor\n82              LassoRegressor\nName: algorithm, Length: 83, dtype: object"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"accuracy = sum(1 for true, pred in zip(actual_data, predictions) if true == pred) / len(actual_data)\naccuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:21:24.481265Z","iopub.execute_input":"2024-11-17T15:21:24.481704Z","iopub.status.idle":"2024-11-17T15:21:24.490059Z","shell.execute_reply.started":"2024-11-17T15:21:24.481660Z","shell.execute_reply":"2024-11-17T15:21:24.489025Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.10843373493975904"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"# save tuned model\r\n","metadata":{}},{"cell_type":"code","source":"# Local saving\nmodel.save_pretrained(\"lora_model\")\ntokenizer.save_pretrained(\"lora_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:21:29.531648Z","iopub.execute_input":"2024-11-17T15:21:29.532671Z","iopub.status.idle":"2024-11-17T15:21:31.805073Z","shell.execute_reply.started":"2024-11-17T15:21:29.532595Z","shell.execute_reply":"2024-11-17T15:21:31.804129Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"('lora_model/tokenizer_config.json',\n 'lora_model/special_tokens_map.json',\n 'lora_model/tokenizer.json')"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"# Online saving on HF\nfrom huggingface_hub import login\n\nnew_model_adabtor= \"ZiadWael/unsloth-Llama3.1-tuned\"\nlogin(token=\"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\")\n\n# Push the model and tokenizer to the Hugging Face hub\nmodel.push_to_hub(new_model_adabtor)\ntokenizer.push_to_hub(new_model_adabtor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:21:37.568205Z","iopub.execute_input":"2024-11-17T15:21:37.568673Z","iopub.status.idle":"2024-11-17T15:21:46.092857Z","shell.execute_reply.started":"2024-11-17T15:21:37.568620Z","shell.execute_reply":"2024-11-17T15:21:46.091905Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/597 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06d1c681c42471db41f6c47eb1e007d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf1460fa9e2d4106a45a16b051056383"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/778M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a681bad45bb74660a81a1604ae23af44"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/ZiadWael/unsloth-Llama3.1-tuned\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Online saving on HF\nmodel.push_to_hub(\"unsloth-Llama-tuned\", use_auth_token='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')\ntokenizer.push_to_hub(\"unsloth-Llama-tuned\", use_auth_token='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')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:22:13.510274Z","iopub.execute_input":"2024-11-17T15:22:13.511055Z","iopub.status.idle":"2024-11-17T15:22:22.130138Z","shell.execute_reply.started":"2024-11-17T15:22:13.511011Z","shell.execute_reply":"2024-11-17T15:22:22.129116Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea36498ae5914d50b1df5482d5077733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71e927fd9004607b99baf05dc7a9373"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/778M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"babbe98f76644fe98a743420ca95e16f"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/unsloth-Llama-tuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d3711e7d3354a48b31e9d27283ffc15"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# Save and Merge to 4bit\nmodel.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit_forced\",token =\"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\")\nmodel.push_to_hub_merged(\"model\", tokenizer, save_method = \"merged_4bit_forced\", token = \"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:22:22.163591Z","iopub.execute_input":"2024-11-17T15:22:22.163984Z","iopub.status.idle":"2024-11-17T15:23:09.822314Z","shell.execute_reply.started":"2024-11-17T15:22:22.163937Z","shell.execute_reply":"2024-11-17T15:23:09.821309Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 4bit...\nThis might take 5 minutes...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Done.\nUnsloth: Saving tokenizer... Done.\nUnsloth: Saving model... This might take 10 minutes for Llama-7b... Done.\nUnsloth: Merging 4bit and LoRA weights to 4bit...\nThis might take 5 minutes...\nDone.\nUnsloth: Saving 4bit Bitsandbytes model. Please wait...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/603 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ed1b94f98db41d18e53e1c3d93f4ea6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07e18d254d8446ae8ac43d263fe574ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d622e603a1c24fbd8e4343e5ee0187ed"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Saved merged_4bit model to https://huggingface.co/model\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Save just LoRA adapters\nmodel.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",token= \"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\")\nmodel.push_to_hub_merged(\"model\", tokenizer, save_method = \"lora\", token = \"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:23:09.880541Z","iopub.execute_input":"2024-11-17T15:23:09.880841Z","iopub.status.idle":"2024-11-17T15:23:17.421910Z","shell.execute_reply.started":"2024-11-17T15:23:09.880809Z","shell.execute_reply":"2024-11-17T15:23:17.420984Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving model... Done.\nUnsloth: Saving LoRA adapters. Please wait...\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Saved lora model to https://huggingface.co/model\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## MLFLOW :https://78d5-35-226-137-11.ngrok-free.app/#/experiments/314000315323789333?viewStateShareKey=154e1803bff3b0eed690da3f40cba0e7e8fc5c0ab16e3803d679c0f49b7eac0d","metadata":{}},{"cell_type":"markdown","source":"# GGUF / llama.cpp Conversion","metadata":{}},{"cell_type":"code","source":"model.push_to_hub_gguf(\"unsloth-llama-ft-gguf\", tokenizer, quantization_method = \"q4_k_m\", token=\"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\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.push_to_hub_merged(\"model\", tokenizer, save_method = \"merged_4bit_forced\", token = \"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\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}