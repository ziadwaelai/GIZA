{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
    "!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
    "!pip install torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install mlflow pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:14.136539Z",
     "iopub.status.busy": "2024-11-17T14:26:14.136165Z",
     "iopub.status.idle": "2024-11-17T14:26:29.111802Z",
     "shell.execute_reply": "2024-11-17T14:26:29.110298Z",
     "shell.execute_reply.started": "2024-11-17T14:26:14.136496Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 #2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = getattr(torch, \"float16\") # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:29.114813Z",
     "iopub.status.busy": "2024-11-17T14:26:29.114443Z",
     "iopub.status.idle": "2024-11-17T14:26:29.119854Z",
     "shell.execute_reply": "2024-11-17T14:26:29.118958Z",
     "shell.execute_reply.started": "2024-11-17T14:26:29.114773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id=\"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:29.121770Z",
     "iopub.status.busy": "2024-11-17T14:26:29.121147Z",
     "iopub.status.idle": "2024-11-17T14:26:39.874773Z",
     "shell.execute_reply": "2024-11-17T14:26:39.873646Z",
     "shell.execute_reply.started": "2024-11-17T14:26:29.121726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.2.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:46.353291Z",
     "iopub.status.busy": "2024-11-17T14:26:46.352526Z",
     "iopub.status.idle": "2024-11-17T14:26:46.359833Z",
     "shell.execute_reply": "2024-11-17T14:26:46.358821Z",
     "shell.execute_reply.started": "2024-11-17T14:26:46.353240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "train_prompt = \"\"\"Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\n",
    "The best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\n",
    "\n",
    "### DESCRIPTION:\n",
    "{}\n",
    "\n",
    "### RESPONSE:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "\n",
    "    inputs       = examples[\"series_description\"]\n",
    "    outputs      = examples[\"algorithm\"]\n",
    "    texts = []\n",
    "    for input, output in zip( inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = train_prompt.format( input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:47.194631Z",
     "iopub.status.busy": "2024-11-17T14:26:47.193962Z",
     "iopub.status.idle": "2024-11-17T14:26:47.364418Z",
     "shell.execute_reply": "2024-11-17T14:26:47.363526Z",
     "shell.execute_reply.started": "2024-11-17T14:26:47.194578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset_name', 'series_description', 'algorithm', 'hyperparameters'],\n",
       "    num_rows: 828\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files='/kaggle/input/regression-univariate-train/Regression_Univariate_train.csv', split='train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:48.320183Z",
     "iopub.status.busy": "2024-11-17T14:26:48.319741Z",
     "iopub.status.idle": "2024-11-17T14:26:48.340682Z",
     "shell.execute_reply": "2024-11-17T14:26:48.339339Z",
     "shell.execute_reply.started": "2024-11-17T14:26:48.320142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and valid sets\n",
    "train_valid_test_split = dataset.train_test_split(test_size=0.2, seed=42)  # 80% train + 20% temp\n",
    "valid_test_split = train_valid_test_split['test'].train_test_split(test_size=0.5, seed=42)  # 10% each for validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:49.075177Z",
     "iopub.status.busy": "2024-11-17T14:26:49.074248Z",
     "iopub.status.idle": "2024-11-17T14:26:49.080096Z",
     "shell.execute_reply": "2024-11-17T14:26:49.078992Z",
     "shell.execute_reply.started": "2024-11-17T14:26:49.075132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_valid_test_split['train']   # 80% train\n",
    "valid_dataset = valid_test_split['train']         # 10% validation\n",
    "test_dataset = valid_test_split['test']           # 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:49.796326Z",
     "iopub.status.busy": "2024-11-17T14:26:49.795928Z",
     "iopub.status.idle": "2024-11-17T14:26:49.854920Z",
     "shell.execute_reply": "2024-11-17T14:26:49.854124Z",
     "shell.execute_reply.started": "2024-11-17T14:26:49.796287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd64f9d8aab4d1190695e02dcaa77bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 144 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 480 minutes, minimum value of -1.2289464767798075, maximum value of 1.21550900898212, median value of 0.0, mean value of -0.0007690196408217143, and average standard deviation of 0.27668995423649856 for the 10 percentiles. The series is detected as stationary using dickey fuller test.The series has 7 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 7 lags ranges from 0.7904835601016195 for the lag number 1 to -0.603704007620162 for the lag number 9. There exist 3 insignificant lags at these indices 2,3,7 between the first and the last significant ones. The series looks to be a additive time-series with a linear trend. There are 1 seasonality components detected in this series represented as sinusoidal waves with periods 20.The series exhibits a skewness value of 0.034566016619103766 and a kurtosis value of 1.4096301230718031. The Fractal dimension analysis yields a value of -0.3197538015832301, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE:\\nSVR<|eot_id|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(formatting_prompts_func, batched = True)\n",
    "train_dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:52.496606Z",
     "iopub.status.busy": "2024-11-17T14:26:52.495804Z",
     "iopub.status.idle": "2024-11-17T14:26:52.534390Z",
     "shell.execute_reply": "2024-11-17T14:26:52.533482Z",
     "shell.execute_reply.started": "2024-11-17T14:26:52.496569Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76f4c7825d447d8aac48bb4bacedbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 206 samples with a missing values percentage of 0.0% imputed using FBProphet model and 8.25242718446602% detected outliers. The target series has a sampling rate of 1440 minutes, minimum value of 750.0, maximum value of 3000.0, median value of 1500.0, mean value of 1625.4901960784314, and average standard deviation of 0.11924729621778932 for the 10 percentiles. The series is detected as non-stationary using dickey fuller testand it turns into a stationary series using first order differencing. The series has only 1 significant laf observed using the partial autocorrelation function (pACF) with value 0.9795278581343962.The series looks to be a multiplicative time-series with a logistic trend. There are 2 seasonality components detected in this series represented as sinusoidal waves with periods 206,68.The series exhibits a skewness value of 0.9341688170988668 and a kurtosis value of 0.284080665836957. The Fractal dimension analysis yields a value of -0.06723616815792989, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE:\\nLassoRegressor<|eot_id|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = valid_dataset.map(formatting_prompts_func, batched = True)\n",
    "valid_dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:53.856465Z",
     "iopub.status.busy": "2024-11-17T14:26:53.856052Z",
     "iopub.status.idle": "2024-11-17T14:26:53.862265Z",
     "shell.execute_reply": "2024-11-17T14:26:53.861177Z",
     "shell.execute_reply.started": "2024-11-17T14:26:53.856426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer_config= {\n",
    "    \"Tokenizer\": tokenizer.__class__.__name__,\n",
    "    \"padding_side\": tokenizer.padding_side,\n",
    "    \"pad_token\": tokenizer.pad_token\n",
    "}\n",
    "model_params ={\n",
    "    \"model_name\": model_id,\n",
    "    \"max_seq_length\": max_seq_length,\n",
    "    \"dtype\": dtype,\n",
    "    \"load_in_4bit\": load_in_4bit,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:26:56.259062Z",
     "iopub.status.busy": "2024-11-17T14:26:56.258641Z",
     "iopub.status.idle": "2024-11-17T14:26:56.907130Z",
     "shell.execute_reply": "2024-11-17T14:26:56.906022Z",
     "shell.execute_reply.started": "2024-11-17T14:26:56.259025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI accessible at: NgrokTunnel: \"https://78d5-35-226-137-11.ngrok-free.app\" -> \"http://localhost:5000\"\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(\"2oySnSA3Uw7Lt3MuzrBoDynO5vG_u1X7wvXRbvPvEBoo3k3U\")\n",
    "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
    "public_url = ngrok.connect(5000, \"http\")\n",
    "print(f\"MLflow UI accessible at: {public_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:28:22.470488Z",
     "iopub.status.busy": "2024-11-17T14:28:22.469541Z",
     "iopub.status.idle": "2024-11-17T14:28:22.910128Z",
     "shell.execute_reply": "2024-11-17T14:28:22.909163Z",
     "shell.execute_reply.started": "2024-11-17T14:28:22.470445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Set MLflow's tracking URI and experiment\n",
    "mlflow.set_tracking_uri(\"https://78d5-35-226-137-11.ngrok-free.app\")\n",
    "mlflow.set_experiment(\"unsloth_Llama_3.1_8B_Regression_Univariate\")\n",
    "mlflow.pytorch.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:28:26.623689Z",
     "iopub.status.busy": "2024-11-17T14:28:26.622187Z",
     "iopub.status.idle": "2024-11-17T14:28:26.631933Z",
     "shell.execute_reply": "2024-11-17T14:28:26.631016Z",
     "shell.execute_reply.started": "2024-11-17T14:28:26.623645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import time\n",
    "class MLFlowLoggingCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.training_loss = []\n",
    "        self.eval_loss = []\n",
    "        self.start = None\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        # Initialize logging at the start of training\n",
    "        self.start= time.time()\n",
    "        print(\"Training started.\")\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # Log training and evaluation losses\n",
    "        if 'loss' in logs:\n",
    "            self.training_loss.append(logs['loss'])\n",
    "            mlflow.log_metric(\"training_loss\", logs['loss'], step=state.global_step)\n",
    "\n",
    "        if 'eval_loss' in logs:\n",
    "            self.eval_loss.append(logs['eval_loss'])\n",
    "            mlflow.log_metric(\"validation_loss\", logs['eval_loss'], step=state.global_step)\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        # Log final results at the end of training\n",
    "        try:\n",
    "            print((time.time()-self.start)/60)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating training duration: {e}\")\n",
    "        print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:28:37.040142Z",
     "iopub.status.busy": "2024-11-17T14:28:37.039673Z",
     "iopub.status.idle": "2024-11-17T14:28:37.056644Z",
     "shell.execute_reply": "2024-11-17T14:28:37.055600Z",
     "shell.execute_reply.started": "2024-11-17T14:28:37.040099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "r = 128\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "use_gradient_checkpointing = \"none\"\n",
    "random_state = 2048\n",
    "use_rslora = False\n",
    "loftq_config = None\n",
    "\n",
    "# Log LoRA configuration to MLflow\n",
    "lora_config = {\n",
    "    \"r\": r,\n",
    "    \"lora_alpha\": lora_alpha,\n",
    "    \"lora_dropout\": lora_dropout,\n",
    "    \"use_gradient_checkpointing\": use_gradient_checkpointing,\n",
    "    \"random_state\": random_state,\n",
    "    \"use_rslora\": use_rslora,\n",
    "    \"loftq_config\": loftq_config,\n",
    "}\n",
    "mlflow.set_tag(\"model_name\", \"Llama3-18B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format datasets\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "valid_dataset = valid_dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA model\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=r,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=use_gradient_checkpointing,\n",
    "    random_state=random_state,\n",
    "    use_rslora=use_rslora,\n",
    "    loftq_config=loftq_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,  \n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    warmup_steps=5,\n",
    "    max_steps=-1,\n",
    "    learning_rate=2e-3,\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    logging_steps=1,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=random_state,\n",
    "    output_dir=\"outputs\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "# Initialize trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    dataset_num_proc=4,\n",
    "    packing=False,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MLflow callback\n",
    "trainer.add_callback(MLFlowLoggingCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:27:00.993688Z",
     "iopub.status.busy": "2024-11-17T14:27:00.993162Z",
     "iopub.status.idle": "2024-11-17T14:27:01.007813Z",
     "shell.execute_reply": "2024-11-17T14:27:01.006692Z",
     "shell.execute_reply.started": "2024-11-17T14:27:00.993635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4. Max memory = 14.741 GB.\n",
      "2.543 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T14:29:00.535997Z",
     "iopub.status.busy": "2024-11-17T14:29:00.535090Z",
     "iopub.status.idle": "2024-11-17T15:19:35.151496Z",
     "shell.execute_reply": "2024-11-17T15:19:35.150538Z",
     "shell.execute_reply.started": "2024-11-17T14:29:00.535954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44237832b874c1caf2f323f3a7febd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a7814a275e402abfc68125c6c70c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.11.7 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3bc82ae1144ad28e0f1deb2894a0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3456d31f21415e9318fcbf5a8398f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/83 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 662 | Num Epochs = 5\n",
      "O^O/ \\_/ \\    Batch size per device = 3 | Gradient Accumulation steps = 16\n",
      "\\        /    Total batch size = 48 | Total steps = 65\n",
      " \"-____-\"     Number of trainable parameters = 194,510,848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mziadwael142\u001b[0m (\u001b[33mziadwael142-giza-systems\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fd2d63e5814b8599811af3d8003414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111345200000263, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241117_142915-q51i0g89</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ziadwael142-giza-systems/huggingface/runs/q51i0g89' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/ziadwael142-giza-systems/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ziadwael142-giza-systems/huggingface' target=\"_blank\">https://wandb.ai/ziadwael142-giza-systems/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ziadwael142-giza-systems/huggingface/runs/q51i0g89' target=\"_blank\">https://wandb.ai/ziadwael142-giza-systems/huggingface/runs/q51i0g89</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 49:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.188000</td>\n",
       "      <td>3.185171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.192500</td>\n",
       "      <td>3.026662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.049800</td>\n",
       "      <td>2.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.718200</td>\n",
       "      <td>2.194016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.213700</td>\n",
       "      <td>1.684431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.708800</td>\n",
       "      <td>1.438652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.476100</td>\n",
       "      <td>1.297304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.304500</td>\n",
       "      <td>1.132477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.141300</td>\n",
       "      <td>1.023324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.069700</td>\n",
       "      <td>0.970793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>0.951199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.977100</td>\n",
       "      <td>0.933737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.921800</td>\n",
       "      <td>0.924610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.530500</td>\n",
       "      <td>0.932627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.918200</td>\n",
       "      <td>0.912293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.932600</td>\n",
       "      <td>0.902027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.915700</td>\n",
       "      <td>0.898832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.905500</td>\n",
       "      <td>0.890322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.916100</td>\n",
       "      <td>0.890837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.911300</td>\n",
       "      <td>0.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.912800</td>\n",
       "      <td>0.881210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.885300</td>\n",
       "      <td>0.881677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.909800</td>\n",
       "      <td>0.880117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.903400</td>\n",
       "      <td>0.880388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.876623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.904200</td>\n",
       "      <td>0.875574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.459000</td>\n",
       "      <td>0.872929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.874600</td>\n",
       "      <td>0.872478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>0.872711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.882300</td>\n",
       "      <td>0.872447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.870708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.875200</td>\n",
       "      <td>0.866881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.875700</td>\n",
       "      <td>0.865746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>0.864797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.851400</td>\n",
       "      <td>0.864220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.864026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0.863324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.884700</td>\n",
       "      <td>0.861897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.860243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.256800</td>\n",
       "      <td>0.859474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.070100</td>\n",
       "      <td>0.857990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.853100</td>\n",
       "      <td>0.857723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.870700</td>\n",
       "      <td>0.859080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.821600</td>\n",
       "      <td>0.859586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.843300</td>\n",
       "      <td>0.857641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.836900</td>\n",
       "      <td>0.855533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.874100</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.872900</td>\n",
       "      <td>0.853593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.856400</td>\n",
       "      <td>0.853110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.842100</td>\n",
       "      <td>0.852016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.851673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.852350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.843600</td>\n",
       "      <td>0.853320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.380900</td>\n",
       "      <td>0.852622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>0.851895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>0.850612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.828700</td>\n",
       "      <td>0.849607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.849121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.862900</td>\n",
       "      <td>0.848821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.849400</td>\n",
       "      <td>0.848456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.814400</td>\n",
       "      <td>0.848269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.848190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.846900</td>\n",
       "      <td>0.848242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.848291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.848294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 14:30:15 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id e36e01a8e14a4fd6b272143744149d9c: Failed to log run data: Exception: API request to https://78d5-35-226-137-11.ngrok-free.app/api/2.0/mlflow/runs/log-batch failed with exception HTTPSConnectionPool(host='78d5-35-226-137-11.ngrok-free.app', port=443): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError('too many 500 error responses'))\n",
      "2024/11/17 14:30:16 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id e36e01a8e14a4fd6b272143744149d9c: Failed to log run data: Exception: API request to https://78d5-35-226-137-11.ngrok-free.app/api/2.0/mlflow/runs/log-batch failed with exception HTTPSConnectionPool(host='78d5-35-226-137-11.ngrok-free.app', port=443): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError('too many 500 error responses'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 15:19:35 INFO mlflow.tracking._tracking_service.client: 🏃 View run illustrious-colt-932 at: https://78d5-35-226-137-11.ngrok-free.app/#/experiments/314000315323789333/runs/e36e01a8e14a4fd6b272143744149d9c.\n",
      "2024/11/17 15:19:35 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://78d5-35-226-137-11.ngrok-free.app/#/experiments/314000315323789333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.57678665717443\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:19:35.322850Z",
     "iopub.status.busy": "2024-11-17T15:19:35.322513Z",
     "iopub.status.idle": "2024-11-17T15:19:35.336933Z",
     "shell.execute_reply": "2024-11-17T15:19:35.335894Z",
     "shell.execute_reply.started": "2024-11-17T15:19:35.322813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak reserved memory = 13.387 GB.\n",
      "Peak reserved memory for training = 10.844 GB.\n",
      "Peak reserved memory % of max memory = 90.815 %.\n",
      "Peak reserved memory for training % of max memory = 73.564 %.\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:19:35.339050Z",
     "iopub.status.busy": "2024-11-17T15:19:35.338642Z",
     "iopub.status.idle": "2024-11-17T15:19:35.569587Z",
     "shell.execute_reply": "2024-11-17T15:19:35.568683Z",
     "shell.execute_reply.started": "2024-11-17T15:19:35.339002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_prompt = \"\"\"Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\n",
    "The best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\n",
    "\n",
    "### DESCRIPTION:\n",
    "{}\n",
    "\n",
    "### RESPONSE:\"\"\"\n",
    "\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    global tokenizer\n",
    "\n",
    "    inputs = examples[\"series_description\"]\n",
    "    texts = []\n",
    "    for input in  inputs:\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = test_prompt.format( input)\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:19:35.571938Z",
     "iopub.status.busy": "2024-11-17T15:19:35.571644Z",
     "iopub.status.idle": "2024-11-17T15:19:36.739900Z",
     "shell.execute_reply": "2024-11-17T15:19:36.738981Z",
     "shell.execute_reply.started": "2024-11-17T15:19:35.571906Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset_name', 'series_description', 'algorithm', 'hyperparameters', 'text'],\n",
       "    num_rows: 83\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(formatting_test_prompts_func, batched = True)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:19:36.741364Z",
     "iopub.status.busy": "2024-11-17T15:19:36.741057Z",
     "iopub.status.idle": "2024-11-17T15:19:38.480325Z",
     "shell.execute_reply": "2024-11-17T15:19:38.479357Z",
     "shell.execute_reply.started": "2024-11-17T15:19:36.741330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 48 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 1440 minutes, minimum value of -1.0577518085465023, maximum value of 0.5039540640878073, median value of -0.5925601507310199, mean value of -0.49076897775897593, and average standard deviation of 0.21373626312059368 for the 10 percentiles. The series is detected as non-stationary using dickey fuller testand it turns into a stationary series using first order differencing. The series has 6 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 6 lags ranges from 0.6091821079108509 for the lag number 1 to 0.3608509812237311 for the lag number 7. There exist 1 insignificant lags at these indices 4 between the first and the last significant ones. The series looks to be a multiplicative time-series with a logistic trend. There are no seasonality components detected in the seriesThe series exhibits a skewness value of 0.6670990699653278 and a kurtosis value of 0.47278337091329936. The Fractal dimension analysis yields a value of -0.4583557992511385, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE: ElasticNetRegressor<|eot_id|>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[test_dataset['text'][0]], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:19:38.482121Z",
     "iopub.status.busy": "2024-11-17T15:19:38.481699Z",
     "iopub.status.idle": "2024-11-17T15:19:39.114210Z",
     "shell.execute_reply": "2024-11-17T15:19:39.113343Z",
     "shell.execute_reply.started": "2024-11-17T15:19:38.482073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 81 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 44640 minutes, minimum value of 3523.548387096774, maximum value of 6434.0, median value of 4978.387096774193, mean value of 4995.464271746457, and average standard deviation of 0.06947531163920204 for the 10 percentiles. The series is detected as stationary using dickey fuller test.The series has 7 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 7 lags ranges from 0.9375534431746181 for the lag number 1 to 0.2340147204900702 for the lag number 7.There are no insignificant lags in between the first and the last significant ones.The series looks to be a multiplicative time-series with a linear trend. There are 1 seasonality components detected in this series represented as sinusoidal waves with periods 27.The series exhibits a skewness value of 0.018459508790673103 and a kurtosis value of 1.0220489598846814. The Fractal dimension analysis yields a value of -0.07028093361365781, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE: ExtraTreesRegressor<|eot_id|>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "[test_dataset['text'][1]], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 5, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:19:39.115834Z",
     "iopub.status.busy": "2024-11-17T15:19:39.115458Z",
     "iopub.status.idle": "2024-11-17T15:20:31.798689Z",
     "shell.execute_reply": "2024-11-17T15:20:31.797420Z",
     "shell.execute_reply.started": "2024-11-17T15:19:39.115784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_responses=[]\n",
    "# get all test data inference result\n",
    "for test_prompt in test_dataset['text']:\n",
    "  inputs= tokenizer(\n",
    "  [test_prompt], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "  outputs = model.generate(**inputs, max_new_tokens = 5, use_cache = True)\n",
    "  test_responses.append(tokenizer.batch_decode(outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:20:43.532399Z",
     "iopub.status.busy": "2024-11-17T15:20:43.531675Z",
     "iopub.status.idle": "2024-11-17T15:20:43.539408Z",
     "shell.execute_reply": "2024-11-17T15:20:43.538557Z",
     "shell.execute_reply.started": "2024-11-17T15:20:43.532350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = test_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:20:44.209306Z",
     "iopub.status.busy": "2024-11-17T15:20:44.208295Z",
     "iopub.status.idle": "2024-11-17T15:20:44.250558Z",
     "shell.execute_reply": "2024-11-17T15:20:44.249665Z",
     "shell.execute_reply.started": "2024-11-17T15:20:44.209254Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>series_description</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>text</th>\n",
       "      <th>model_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>GaussianProcessRegressor</td>\n",
       "      <td>{'alpha': 0.01, 'kernel': 1**2 * RBF(length_sc...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M36312_train.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>GaussianProcessRegressor</td>\n",
       "      <td>{'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>GaussianProcessRegressor</td>\n",
       "      <td>{'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>ElasticNetRegressor</td>\n",
       "      <td>{'l1_ratio': 0.7666666666666666, 'random_state...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0.9, 'learn...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>W221_train.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>ElasticNetRegressor</td>\n",
       "      <td>{'l1_ratio': 1.0, 'random_state': 42, 'selecti...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>449.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>{'colsample_bytree': 1.0, 'gamma': 3.996320950...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>395.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>AdaboostRegressor</td>\n",
       "      <td>{'estimator': DecisionTreeRegressor(max_depth=...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>11.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>AdaboostRegressor</td>\n",
       "      <td>{'estimator': DecisionTreeRegressor(max_depth=...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>M37780_train.csv</td>\n",
       "      <td>A univariate time-series dataset  consists of ...</td>\n",
       "      <td>LassoRegressor</td>\n",
       "      <td>{'alpha': 0.24381437457499952, 'random_state':...</td>\n",
       "      <td>Below is a description for a time series data....</td>\n",
       "      <td>[&lt;|begin_of_text|&gt;Below is a description for a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset_name                                 series_description  \\\n",
       "0             33.csv  A univariate time-series dataset  consists of ...   \n",
       "1   M36312_train.csv  A univariate time-series dataset  consists of ...   \n",
       "2            134.csv  A univariate time-series dataset  consists of ...   \n",
       "3            222.csv  A univariate time-series dataset  consists of ...   \n",
       "4             75.csv  A univariate time-series dataset  consists of ...   \n",
       "..               ...                                                ...   \n",
       "78    W221_train.csv  A univariate time-series dataset  consists of ...   \n",
       "79           449.csv  A univariate time-series dataset  consists of ...   \n",
       "80           395.csv  A univariate time-series dataset  consists of ...   \n",
       "81            11.csv  A univariate time-series dataset  consists of ...   \n",
       "82  M37780_train.csv  A univariate time-series dataset  consists of ...   \n",
       "\n",
       "                   algorithm  \\\n",
       "0   GaussianProcessRegressor   \n",
       "1   GaussianProcessRegressor   \n",
       "2   GaussianProcessRegressor   \n",
       "3        ElasticNetRegressor   \n",
       "4           XGBoostRegressor   \n",
       "..                       ...   \n",
       "78       ElasticNetRegressor   \n",
       "79          XGBoostRegressor   \n",
       "80         AdaboostRegressor   \n",
       "81         AdaboostRegressor   \n",
       "82            LassoRegressor   \n",
       "\n",
       "                                      hyperparameters  \\\n",
       "0   {'alpha': 0.01, 'kernel': 1**2 * RBF(length_sc...   \n",
       "1   {'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...   \n",
       "2   {'alpha': 0.01, 'kernel': DotProduct(sigma_0=0...   \n",
       "3   {'l1_ratio': 0.7666666666666666, 'random_state...   \n",
       "4   {'colsample_bytree': 0.5, 'gamma': 0.9, 'learn...   \n",
       "..                                                ...   \n",
       "78  {'l1_ratio': 1.0, 'random_state': 42, 'selecti...   \n",
       "79  {'colsample_bytree': 1.0, 'gamma': 3.996320950...   \n",
       "80  {'estimator': DecisionTreeRegressor(max_depth=...   \n",
       "81  {'estimator': DecisionTreeRegressor(max_depth=...   \n",
       "82  {'alpha': 0.24381437457499952, 'random_state':...   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Below is a description for a time series data....   \n",
       "1   Below is a description for a time series data....   \n",
       "2   Below is a description for a time series data....   \n",
       "3   Below is a description for a time series data....   \n",
       "4   Below is a description for a time series data....   \n",
       "..                                                ...   \n",
       "78  Below is a description for a time series data....   \n",
       "79  Below is a description for a time series data....   \n",
       "80  Below is a description for a time series data....   \n",
       "81  Below is a description for a time series data....   \n",
       "82  Below is a description for a time series data....   \n",
       "\n",
       "                                      model_responses  \n",
       "0   [<|begin_of_text|>Below is a description for a...  \n",
       "1   [<|begin_of_text|>Below is a description for a...  \n",
       "2   [<|begin_of_text|>Below is a description for a...  \n",
       "3   [<|begin_of_text|>Below is a description for a...  \n",
       "4   [<|begin_of_text|>Below is a description for a...  \n",
       "..                                                ...  \n",
       "78  [<|begin_of_text|>Below is a description for a...  \n",
       "79  [<|begin_of_text|>Below is a description for a...  \n",
       "80  [<|begin_of_text|>Below is a description for a...  \n",
       "81  [<|begin_of_text|>Below is a description for a...  \n",
       "82  [<|begin_of_text|>Below is a description for a...  \n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model_responses']= test_responses\n",
    "df.to_csv('test_model_result_unsloth.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:20:48.609368Z",
     "iopub.status.busy": "2024-11-17T15:20:48.608653Z",
     "iopub.status.idle": "2024-11-17T15:20:48.616952Z",
     "shell.execute_reply": "2024-11-17T15:20:48.616006Z",
     "shell.execute_reply.started": "2024-11-17T15:20:48.609323Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>Below is a description for a time series data. Write a response that gives the name of the best fitting machine learning algorithm in one word without explanation.\\nThe best algorithm name should be one of this search space algorithms: AdaboostRegressor, ElasticNetRegressor,  ExtraTreesRegressor,  LassoRegressor,  LightgbmRegressor, SVR, GaussianProcessRegressor, RandomForestRegressor or  XGBoostRegressor.\\n\\n### DESCRIPTION:\\nA univariate time-series dataset  consists of 81 samples with a missing values percentage of 0.0% imputed using FBProphet model and 0.0% detected outliers. The target series has a sampling rate of 44640 minutes, minimum value of 3523.548387096774, maximum value of 6434.0, median value of 4978.387096774193, mean value of 4995.464271746457, and average standard deviation of 0.06947531163920204 for the 10 percentiles. The series is detected as stationary using dickey fuller test.The series has 7 significant lags observed using the partial autocorrelation function (pACF), the pACF values for these 7 lags ranges from 0.9375534431746181 for the lag number 1 to 0.2340147204900702 for the lag number 7.There are no insignificant lags in between the first and the last significant ones.The series looks to be a multiplicative time-series with a linear trend. There are 1 seasonality components detected in this series represented as sinusoidal waves with periods 27.The series exhibits a skewness value of 0.018459508790673103 and a kurtosis value of 1.0220489598846814. The Fractal dimension analysis yields a value of -0.07028093361365781, indicating a Complex and irregular time-series structure. The dataset is converted into a simple regression task by extracting the previously described features.\\n\\n### RESPONSE: AdaboostRegressor<|eot_id|>']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_responses[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:20:52.861417Z",
     "iopub.status.busy": "2024-11-17T15:20:52.860459Z",
     "iopub.status.idle": "2024-11-17T15:20:52.872381Z",
     "shell.execute_reply": "2024-11-17T15:20:52.871348Z",
     "shell.execute_reply.started": "2024-11-17T15:20:52.861367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GaussianProcessRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'GaussianProcessRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'SVR',\n",
       " 'SVR',\n",
       " 'ExtraTreesRegressor',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'SVR',\n",
       " 'SVR',\n",
       " 'ElasticNetRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'GaussianProcessRegressor',\n",
       " 'SVR',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'GaussianProcessRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'GaussianProcessRegressor',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor',\n",
       " 'GaussianProcessRegressor',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'SVR',\n",
       " 'ElasticNetRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'GaussianProcessRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'AdaboostRegressor',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'GaussianProcessRegressor',\n",
       " 'ElasticNetRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'SVR',\n",
       " 'ElasticNetRegressor',\n",
       " 'SVR',\n",
       " 'SVR',\n",
       " 'AdaboostRegressor']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for response in test_responses:\n",
    "    try:\n",
    "        prediction = response[0].split('\\n\\n### RESPONSE:')[1].split('</s>')[0].strip()        \n",
    "        clean_prediction = prediction.split('<|eot_id|>')[0].strip()        \n",
    "        predictions.append(clean_prediction)\n",
    "    except IndexError:\n",
    "        predictions.append(\"Invalid response\")\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:21:01.266766Z",
     "iopub.status.busy": "2024-11-17T15:21:01.266331Z",
     "iopub.status.idle": "2024-11-17T15:21:01.274440Z",
     "shell.execute_reply": "2024-11-17T15:21:01.273357Z",
     "shell.execute_reply.started": "2024-11-17T15:21:01.266726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:21:20.918302Z",
     "iopub.status.busy": "2024-11-17T15:21:20.917532Z",
     "iopub.status.idle": "2024-11-17T15:21:20.925429Z",
     "shell.execute_reply": "2024-11-17T15:21:20.924502Z",
     "shell.execute_reply.started": "2024-11-17T15:21:20.918258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data= df['algorithm']\n",
    "len(actual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:21:22.321131Z",
     "iopub.status.busy": "2024-11-17T15:21:22.320465Z",
     "iopub.status.idle": "2024-11-17T15:21:22.330219Z",
     "shell.execute_reply": "2024-11-17T15:21:22.329319Z",
     "shell.execute_reply.started": "2024-11-17T15:21:22.321089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     GaussianProcessRegressor\n",
       "1     GaussianProcessRegressor\n",
       "2     GaussianProcessRegressor\n",
       "3          ElasticNetRegressor\n",
       "4             XGBoostRegressor\n",
       "                ...           \n",
       "78         ElasticNetRegressor\n",
       "79            XGBoostRegressor\n",
       "80           AdaboostRegressor\n",
       "81           AdaboostRegressor\n",
       "82              LassoRegressor\n",
       "Name: algorithm, Length: 83, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:21:24.481704Z",
     "iopub.status.busy": "2024-11-17T15:21:24.481265Z",
     "iopub.status.idle": "2024-11-17T15:21:24.490059Z",
     "shell.execute_reply": "2024-11-17T15:21:24.489025Z",
     "shell.execute_reply.started": "2024-11-17T15:21:24.481660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15843373493975904"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(1 for true, pred in zip(actual_data, predictions) if true == pred) / len(actual_data)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:21:29.532671Z",
     "iopub.status.busy": "2024-11-17T15:21:29.531648Z",
     "iopub.status.idle": "2024-11-17T15:21:31.805073Z",
     "shell.execute_reply": "2024-11-17T15:21:31.804129Z",
     "shell.execute_reply.started": "2024-11-17T15:21:29.532595Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local saving\n",
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:21:37.568673Z",
     "iopub.status.busy": "2024-11-17T15:21:37.568205Z",
     "iopub.status.idle": "2024-11-17T15:21:46.092857Z",
     "shell.execute_reply": "2024-11-17T15:21:46.091905Z",
     "shell.execute_reply.started": "2024-11-17T15:21:37.568620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06d1c681c42471db41f6c47eb1e007d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/597 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1460fa9e2d4106a45a16b051056383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a681bad45bb74660a81a1604ae23af44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/778M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/ZiadWael/unsloth-Llama3.1-tuned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    }
   ],
   "source": [
    "# Online saving on HF\n",
    "from huggingface_hub import login\n",
    "\n",
    "new_model_adabtor= \"ZiadWael/unsloth-Llama3.1-tuned\"\n",
    "login(token=\"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\")\n",
    "\n",
    "# Push the model and tokenizer to the Hugging Face hub\n",
    "model.push_to_hub(new_model_adabtor)\n",
    "tokenizer.push_to_hub(new_model_adabtor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:22:13.511055Z",
     "iopub.status.busy": "2024-11-17T15:22:13.510274Z",
     "iopub.status.idle": "2024-11-17T15:22:22.130138Z",
     "shell.execute_reply": "2024-11-17T15:22:22.129116Z",
     "shell.execute_reply.started": "2024-11-17T15:22:13.511011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea36498ae5914d50b1df5482d5077733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71e927fd9004607b99baf05dc7a9373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babbe98f76644fe98a743420ca95e16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/778M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/unsloth-Llama-tuned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3711e7d3354a48b31e9d27283ffc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    }
   ],
   "source": [
    "# Online saving on HF\n",
    "model.push_to_hub(\"unsloth-Llama-tuned\", use_auth_token='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')\n",
    "tokenizer.push_to_hub(\"unsloth-Llama-tuned\", use_auth_token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:22:22.163984Z",
     "iopub.status.busy": "2024-11-17T15:22:22.163591Z",
     "iopub.status.idle": "2024-11-17T15:23:09.822314Z",
     "shell.execute_reply": "2024-11-17T15:23:09.821309Z",
     "shell.execute_reply.started": "2024-11-17T15:22:22.163937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
      "This might take 5 minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 10 minutes for Llama-7b... Done.\n",
      "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
      "This might take 5 minutes...\n",
      "Done.\n",
      "Unsloth: Saving 4bit Bitsandbytes model. Please wait...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed1b94f98db41d18e53e1c3d93f4ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/603 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e18d254d8446ae8ac43d263fe574ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d622e603a1c24fbd8e4343e5ee0187ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged_4bit model to https://huggingface.co/model\n"
     ]
    }
   ],
   "source": [
    "# Save and Merge to 4bit\n",
    "model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit_forced\",token =\"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\")\n",
    "model.push_to_hub_merged(\"model\", tokenizer, save_method = \"merged_4bit_forced\", token = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T15:23:09.880841Z",
     "iopub.status.busy": "2024-11-17T15:23:09.880541Z",
     "iopub.status.idle": "2024-11-17T15:23:17.421910Z",
     "shell.execute_reply": "2024-11-17T15:23:17.420984Z",
     "shell.execute_reply.started": "2024-11-17T15:23:09.880809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... Done.\n",
      "Unsloth: Saving LoRA adapters. Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lora model to https://huggingface.co/model\n"
     ]
    }
   ],
   "source": [
    "# Save just LoRA adapters\n",
    "model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",token= \"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\")\n",
    "model.push_to_hub_merged(\"model\", tokenizer, save_method = \"lora\", token = \"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFLOW :https://78d5-35-226-137-11.ngrok-free.app/#/experiments/314000315323789333?viewStateShareKey=154e1803bff3b0eed690da3f40cba0e7e8fc5c0ab16e3803d679c0f49b7eac0d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GGUF / llama.cpp Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub_gguf(\"unsloth-llama-ft-gguf\", tokenizer, quantization_method = \"q4_k_m\", token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub_merged(\"model\", tokenizer, save_method = \"merged_4bit_forced\", token = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6104747,
     "sourceId": 9931323,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
